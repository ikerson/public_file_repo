{
    "E001": "Low-level memory access violation",
    "E002": "Network timeout",
    "E003": "Insufficient GPT buffers",
    "E004": "Insufficient memory allocation",
    "E005": "Hardware access error",
    "E006": "Database connection timeout",
    "E007": "GPU temperature threshold exceeded",
    "E008": "Invalid API key provided",
    "E009": "Unexpected token in JSON payload",
    "E010": "Prompt token limit exceeded",
    "E011": "Invalid model configuration",
    "E012": "Model not found in registry",
    "E013": "Unsupported operation requested",
    "E014": "Input text contains restricted content",
    "E015": "Model response generation timeout",
    "E016": "Failed to fetch embeddings from RAG system",
    "E017": "Cache server unresponsive",
    "E018": "Language mismatch in input and model settings",
    "E019": "Rate limit exceeded for API requests",
    "E020": "LLM model checkpoint corrupted",
    "E021": "Invalid user input format",
    "E022": "Inference engine overload detected",
    "E023": "Session state inconsistency",
    "E024": "Failed to decode model output",
    "E999": "Log trace error test",
    "E404": "Error code reference not found"
}